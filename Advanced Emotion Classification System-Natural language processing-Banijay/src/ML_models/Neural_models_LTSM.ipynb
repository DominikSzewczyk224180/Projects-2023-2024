{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import re                                  \n",
    "import string  \n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords          \n",
    "from nltk.stem import PorterStemmer        \n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_emotions = pd.read_csv(r\"C:\\Users\\domin\\Desktop\\Year 2 Block C\\2023-24c-fai2-adsai-DominikSzewczyk224180\\Datasets\\simplified_emotions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(simplified_emotions['sentence'], simplified_emotions['emotion'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "y_train = labelencoder.fit_transform(y_train)\n",
    "y_test = labelencoder.transform(y_test)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_processor(sentence):\n",
    "    sentence = re.sub('https?\\S+|#+', '', sentence)\n",
    "\n",
    "    sentence = re.sub('#', '', sentence)\n",
    "\n",
    "    tokenizer = word_tokenize\n",
    "\n",
    "    processed_sentence = tokenizer(sentence)\n",
    "\n",
    "    stopwords_english = set(stopwords.words('english'))\n",
    "    processed_sentence = [word for word in processed_sentence if word.lower() not in stopwords_english]\n",
    "\n",
    "    processed_sentence = [word for word in processed_sentence if word.lower() not in string.punctuation]\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    processed_sentence = [stemmer.stem(word) for word in processed_sentence]\n",
    "\n",
    "    return processed_sentence\n",
    "\n",
    "def sentence_processor_df(df):\n",
    "    processed_sentences_list = []\n",
    "    for sentence in df:\n",
    "        processed_sentence = sentence_processor(sentence)\n",
    "        processed_sentences_list.append(processed_sentence)\n",
    "    return processed_sentences_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sentence_processor_df(X_train)\n",
    "\n",
    "train_sentences_str = []\n",
    "for token in X_train:\n",
    "    train_sentences_str.append(' '.join(token)) \n",
    "\n",
    "X_test = sentence_processor_df(X_test)\n",
    "\n",
    "test_sentences_str = []\n",
    "for token in X_test:\n",
    "    test_sentences_str.append(' '.join(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters = '')\n",
    "tokenizer.fit_on_texts(train_sentences_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77384\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(train_sentences_str)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sequences = tokenizer.texts_to_sequences(train_sentences_str)\n",
    "training_padded = pad_sequences(training_sequences, padding='post',maxlen = 30) \n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences_str)\n",
    "test_padded = pad_sequences(test_sequences, padding='post',maxlen = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_padded\n",
    "X_test = test_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 30, 100)           7738400   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               117248    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,921,826\n",
      "Trainable params: 7,921,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, SimpleRNN, LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=100, input_length=30))\n",
    "model.add(LSTM(units=128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4837/4837 [==============================] - 393s 81ms/step - loss: 0.6551 - accuracy: 0.7486 - val_loss: 0.5390 - val_accuracy: 0.7397\n",
      "Epoch 2/3\n",
      "4837/4837 [==============================] - 397s 82ms/step - loss: 0.5163 - accuracy: 0.7479 - val_loss: 0.5230 - val_accuracy: 0.7397\n",
      "Epoch 3/3\n",
      "4837/4837 [==============================] - 335s 69ms/step - loss: 0.4962 - accuracy: 0.7477 - val_loss: 0.5387 - val_accuracy: 0.7397\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=3, batch_size=16, validation_data = (X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 5s 8ms/step\n",
      "Accuracy: 0.7396877907577794\n",
      "F1 Score: 0.42518421678155455\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
    "f1 = f1_score(y_test_labels, y_pred_labels, average='macro')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_test = pd.read_csv(r\"C:\\Users\\domin\\Desktop\\Year 2 Block C\\2023-24c-fai2-adsai-DominikSzewczyk224180\\Datasets\\test.csv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "tokenized_test_sentences = tokenizer.texts_to_sequences(kaggle_test['sentence'])\n",
    "padded_test_sentences = pad_sequences(tokenized_test_sentences, maxlen=30)\n",
    "\n",
    "predictions = model.predict(padded_test_sentences)\n",
    "\n",
    "predicted_labels = ['happiness' if pred.argmax() == 1 else 'other' for pred in predictions]\n",
    "\n",
    "results_df = pd.DataFrame({'id': range(len(kaggle_test)), 'emotion': predicted_labels})\n",
    "\n",
    "results_df.to_csv('predictions_LSTM_model.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
