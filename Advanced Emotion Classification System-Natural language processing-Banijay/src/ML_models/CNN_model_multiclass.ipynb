{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import re                                  \n",
    "import string  \n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords          \n",
    "from nltk.stem import PorterStemmer        \n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotions = pd.read_csv(r\"C:\\Users\\domin\\Desktop\\Year 2 Block C\\2023-24c-fai2-adsai-DominikSzewczyk224180\\Datasets\\emotion_data_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What?</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hey!</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Where?!</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>No, I know!</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Well! Well! Well! Joey Tribbiani! So you came ...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence    emotion\n",
       "0                                               What?   surprise\n",
       "3                                                Hey!  happiness\n",
       "5                                             Where?!   surprise\n",
       "8                                         No, I know!   surprise\n",
       "13  Well! Well! Well! Joey Tribbiani! So you came ...   surprise"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emotions = df_emotions [df_emotions ['emotion'] != 'neutral']\n",
    "df_emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_emotions['sentence'], df_emotions['emotion'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "y_train = labelencoder.fit_transform(y_train)\n",
    "y_test = labelencoder.transform(y_test)\n",
    "y_val = labelencoder.transform(y_val)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_processor(sentence):\n",
    "    sentence = re.sub('https?\\S+|#+', '', sentence)\n",
    "\n",
    "    sentence = re.sub('#', '', sentence)\n",
    "\n",
    "    tokenizer = word_tokenize\n",
    "\n",
    "    processed_sentence = tokenizer(sentence)\n",
    "\n",
    "    stopwords_english = set(stopwords.words('english'))\n",
    "    processed_sentence = [word for word in processed_sentence if word.lower() not in stopwords_english]\n",
    "\n",
    "    processed_sentence = [word for word in processed_sentence if word.lower() not in string.punctuation]\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    processed_sentence = [stemmer.stem(word) for word in processed_sentence]\n",
    "\n",
    "    return processed_sentence\n",
    "\n",
    "def sentence_processor_df(df):\n",
    "    processed_sentences_list = []\n",
    "    for sentence in df:\n",
    "        processed_sentence = sentence_processor(sentence)\n",
    "        processed_sentences_list.append(processed_sentence)\n",
    "    return processed_sentences_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sentence_processor_df(X_train)\n",
    "\n",
    "train_sentences_str = []\n",
    "for token in X_train:\n",
    "    train_sentences_str.append(' '.join(token)) \n",
    "\n",
    "X_test = sentence_processor_df(X_test)\n",
    "\n",
    "test_sentences_str = []\n",
    "for token in X_test:\n",
    "    test_sentences_str.append(' '.join(token))\n",
    "\n",
    "X_val = sentence_processor_df(X_val)\n",
    "\n",
    "val_sentences_str = []\n",
    "for token in X_val:\n",
    "    val_sentences_str.append(' '.join(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters = '')\n",
    "tokenizer.fit_on_texts(train_sentences_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38692\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(train_sentences_str)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sequences = tokenizer.texts_to_sequences(train_sentences_str)\n",
    "training_padded = pad_sequences(training_sequences, padding='post',maxlen = 30) \n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences_str)\n",
    "test_padded = pad_sequences(test_sequences, padding='post',maxlen = 30)\n",
    "\n",
    "val_sequences = tokenizer.texts_to_sequences(val_sentences_str)\n",
    "val_padded = pad_sequences(val_sequences, padding='post',maxlen = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_padded\n",
    "X_test = test_padded\n",
    "X_val = val_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 6\n",
    "max_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=2, input_length=max_length))\n",
    "model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2419/2419 [==============================] - 10s 4ms/step - loss: 1.2472 - accuracy: 0.5267 - val_loss: 1.1941 - val_accuracy: 0.5494\n",
      "Epoch 2/3\n",
      "2419/2419 [==============================] - 10s 4ms/step - loss: 1.0953 - accuracy: 0.5978 - val_loss: 1.1226 - val_accuracy: 0.5953\n",
      "Epoch 3/3\n",
      "2419/2419 [==============================] - 12s 5ms/step - loss: 1.0122 - accuracy: 0.6368 - val_loss: 1.1293 - val_accuracy: 0.5850\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=3, batch_size=16, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step\n",
      "Accuracy: 0.5896872576893254\n",
      "F1 Score: 0.3607902788859847\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
    "f1 = f1_score(y_test_labels, y_pred_labels, average='macro')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_test_df = pd.read_csv(r\"C:\\Users\\domin\\Desktop\\Year 2 Block C\\2023-24c-fai2-adsai-DominikSzewczyk224180\\Datasets\\test.csv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_test = sentence_processor_df(kaggle_test_df['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_test1 = []\n",
    "for token in kaggle_test:\n",
    "    kaggle_test1.append(' '.join(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_test_sequences = tokenizer.texts_to_sequences(kaggle_test1)\n",
    "kaggle_test_padded = pad_sequences(kaggle_test_sequences, maxlen=30, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_kaggle = model.predict(kaggle_test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_kaggle = np.argmax(y_pred_kaggle, axis=1)\n",
    "y_pred_kaggle = labelencoder.inverse_transform(y_pred_kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({'id': kaggle_test_df['id'], 'emotion': y_pred_kaggle})\n",
    "predictions.to_csv('predictions_CNN.csv', index=False, sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
